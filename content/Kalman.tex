\chapter{EKF (Extended Kalman Filter)}
\section{Used Packages}
\subsection{Robot localization}
For the functionality of the kalman filtered the package robot\_localization was used. The advantage of this package is the 15-dimensional implementation of the kalman filter with direct support for a 6D-Pose, 6D-Velocity and a 3D-Acceleration Vector. The available inputs can be dynamically configured in the launchfile for the robot\_localization node. In general the whole package is configurable via launch or yaml file.
\subsection{TF}
The TF package is used to define all sorts of Transformations of data in different coordinate systems. In this case the robot's map data and the input of the marker detection are converted to be fused in a common coordinate system. 
\section{Package Structure / Design}
\subsection{Configuration}
The Kalman package is highly dynamic. All properties and settings can be configured by yaml and launchfiles as by the robot\_localization package. So there is no recompilation required if topic names are changed or the resulting frames of the data change.
\subsection{Robot Localization Node}
This node is a part of the robot\_localization package and implements the extended kalman filter. It gets input from the topics of the Vision group, the robot's map system and a third topic generated by the Kalman converter node in case the robot is kidnapped to prevent the continuous detection of kidnappings due to jumping output values.
\subsection{Converter Node}
The converter node handles the output of the robot\_localization node and republishes the data to the final topic, the other groups are working with. This interception is used to filter all results of the robot's map data and only rely on camera data as long as the robot is in kidnapped state. Moreover the converter node publishes the camera results with reduced covariance as a third input topic to the kalman filter, to convince it that the camera data now has the only valid results. This is needed since the ranges of covariances between the different input topics vary vastly.
\section{Testing}
\subsection{Matlab Parameter Simulation}
In the beginning of the project a simulation in matlab of a kalman filter was created to experiment with the different parameters of a kalman filter and how they influence the results. Especially the kalman model got more clear when inserting velocity data and seeing the prediction results of the kalman filter. Moreover the effects of the noise covariances where understood in a way that was very helpful throughout the project.
\subsection{Test Data Generation}
In the first months of the project it was very difficult to test the implementation since the other teams had been still in development too. To overcome that obstacle artifical test data was generated with two approaches.
\subsubsection{Matlab}
In Matlab the generation of test data was done by supplying some points in time and then using a cubic spline interpolation to generate the values in between. For simplicity this values where initally generated only for one dimension of the kalman filter.
\subsubsection{Simple MonoGame}
For the generation of more realistic values concerning 2D pose of the robot and the view angle a small program was created. This program used the MonoGame framework to interact with the mouse on a small window. A small arrow was displayed to represent the robot. A user could click on a position to tell the robot to move their with a fixed speed, that was defined in advance. When holding down the mouse button and releasing it on an other pixel the vector between these points was used to generate the target view angle of the robot. The program continuously outputs the current position and view angle of the robot to a file.
\subsection{Sensor Test Data Dummy node}
The generated test data is loaded by test sensor nodes that publish the data from the input files in a loop. The purpose of this dummy nodes is to enable testing the other nodes, especially the kalman filter. This way it was possible to tweak the parameters of the robot\_localization node independently of the other groups.
\subsection{Rviz Simulation}
As soon as test data was available and reached the kalman filter as input it was hard to determine how good the results actually are, since humans are not very effective in classificating text data. Therefore the ROS package rviz was selected to output the results of the topics and have a visual proof for the effects of parameter changes.
\subsection{visualization node}
The visualization node subscribes to the output topic of the kalman filter and the input topcis from the robot to create displayable data which can be used to verify how appropriate the fusion of the inputs actually works. This displayable data are markers that get published to rviz which then outputs the robots position. Their are to possible modes of the visualization. Show the current 2D Pose of the robot or show timely change of the x-value of the robots pose. Also it is possible to output the behaviour of the covariances over time to have a better understanding why there might be a sudden change in the behavior of the kalman filter.
\section{Problems}
\subsection{No Data from USB stick}
When the kalman filtered worked satisfactory with the artifical test data, the first approach to get more realistic data was to get data from the robot simulator. As the installation of MCA2 and the simulator was a real pain, it was finally discovered that additional data only existing on a USB drive was required to get it running. Even when receiving the data from the high level group it was still not possible to run the simulator on our private machines. By that time information on how to get data from the real robot and how to correctly initialize the software on it was available. So it was directly started to test with data generated by the robot itself.
\subsection{Incorrect/outdated contradictory documentation}
TODO
\subsection{Roslaunch initialization and ROS\_IP behind NATs}
While working with virtual machines for ROS package development the problem of incorrect communication between the packages was discovered. Only when starting the nodes in the right order with appropriate delays in between the system would work on the robot. In general the specificatioin of the ROS\_IP environment variable is used to solve that issue. The local IP of the virtual machines behind a NAT was not available and so the execution of the nodes was completly moved to the robot.
\subsection{Started with own Kalman Impl}
Before using the robot\_localization package a short approach was started to implement the kalman filter by hand. Luckily the hint on the robot\_localization package was received before more than the subscription and publishing of data was implemented, which became reused throughout the project.
\subsection{WLAN Overload -> huge delay}
When attaching the camera to the robot in a manner that, the image data has to be sent by WLAN, the whole ROS communication is extremly slow. This problem was solved by the complete installation of drivers for the camera on the robot. So the camera and the nodes of the vision group could operate completely local on the robot.
\subsection{Boundary of max valid jumps between values}
When first configuring the robot\_localization package a threshold for maximal valid jumps in data was set to a rather low value. This later caused a lot of unexpected behavior in the kalman filter with not respecting changes in one sensor at all. After setting this threshold to an appropriate value the filter worked even better as initally expected. This was based on the good values for the remaining parameters of the kalman filter, which had previously been well tested with the Matlab simulation.
\subsection{Set pose of robot\_localization does not work as expected}
The robot\_localization package provides a set\_pose topic to force the actual pose of the robot. Unfortunately this sets the pose permanently and further input is ignored. This was not satisfying to implement a special behavior for the case the robot is kidnapped. The final approach uses a third input sensor that is filled with the approriate data and very low covariances to convince the kalman filter of the real current position.
\subsection{Unclear information about the data source topics and types for the data fusion}
It was kind of an odyssey to find out which scripts to start on the robot to have the input topics available. During some periods alternative topics where used to at least gather some data from the robot. This was the case with the map position data of the robot which was temporarily replaced by the odometry values of the robot.